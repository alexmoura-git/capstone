{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c98c5c4",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c659d642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine, inspect\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tqdm\n",
    "import random\n",
    "\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('max_rows', 250)\n",
    "pd.set_option('display.max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98f3284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ingest_data(list_of_cities,list_of_files):\n",
    "\n",
    "\n",
    "    folder_path = \"data\"\n",
    "\n",
    "    df_dic = {}\n",
    "    geojson_list =[]\n",
    "    for city in list_of_cities:\n",
    "\n",
    "        # List all files in the folder\n",
    "        full_path = folder_path +'/'+ city \n",
    "        files = os.listdir(full_path  )\n",
    "        for file in files:\n",
    "            if file in list_of_files:\n",
    "                df=pd.DataFrame()\n",
    "                if file.endswith(('.gz')):\n",
    "                    df = pd.read_csv(full_path + '/' + file , compression='gzip')\n",
    "                elif file.endswith(('.geojson')):\n",
    "                    with open(os.path.join(full_path, file)) as f:\n",
    "                        data = json.load(f)\n",
    "                        geojson_list.append((city,snapshot,file, data))\n",
    "                elif file.endswith(('.csv')):\n",
    "                    df = pd.read_csv(full_path + '/' + file )\n",
    "                df['city'] = city\n",
    "                df['file']=file\n",
    "\n",
    "                if file.endswith(('.gz', '.csv')):\n",
    "                    if file.replace(\".\",'_') in df_dic:\n",
    "                        df_dic[file.replace(\".\",'_')]= pd.concat([df_dic[file.replace(\".\",'_')],df]) \\\n",
    "                                                         .drop_duplicates()\n",
    "                    else: \n",
    "                        df_dic[file.replace(\".\",'_')]=df\n",
    "                    print(full_path + '/' + file)\n",
    "\n",
    "\n",
    "    # Saving it to pickle as an intermediary step\n",
    "\n",
    "    for key in df_dic:\n",
    "            # Shuffle the data\n",
    "        df_dic[key] = df_dic[key].sample(frac=1).reset_index(drop=True)\n",
    "        df_dic[key].to_pickle(key + \".pkl\")\n",
    "        print (key, 'Save as pickle')\n",
    "    \n",
    "    return\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd53bc8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/asheville/listings.csv.gz\n",
      "data/austin/listings.csv.gz\n",
      "data/boston/listings.csv.gz\n",
      "data/broward-county/listings.csv.gz\n",
      "data/cambridge/listings.csv.gz\n",
      "data/chicago/listings.csv.gz\n",
      "data/clark-county/listings.csv.gz\n",
      "data/columbus/listings.csv.gz\n",
      "data/dallas/listings.csv.gz\n",
      "data/denver/listings.csv.gz\n",
      "data/hawaii/listings.csv.gz\n",
      "data/jersey-city/listings.csv.gz\n",
      "data/los-angeles/listings.csv.gz\n",
      "data/nashville/listings.csv.gz\n",
      "data/new-orleans/listings.csv.gz\n",
      "data/new-york-city/listings.csv.gz\n",
      "data/oakland/listings.csv.gz\n",
      "data/pacific-grove/listings.csv.gz\n",
      "data/portland/listings.csv.gz\n",
      "data/salem/listings.csv.gz\n",
      "data/san-diego/listings.csv.gz\n",
      "data/san-francisco/listings.csv.gz\n",
      "data/san-mateo-county/listings.csv.gz\n",
      "data/santa-cruz-county/listings.csv.gz\n",
      "data/seattle/listings.csv.gz\n",
      "data/twin-cities/listings.csv.gz\n",
      "data/washington-dc/listings.csv.gz\n",
      "listings_csv_gz Save as pickle\n"
     ]
    }
   ],
   "source": [
    "list_of_cities =  [\n",
    "    'asheville',\n",
    "    'austin',\n",
    "    'boston',\n",
    "    'broward-county',\n",
    "    'cambridge',\n",
    "    'chicago',\n",
    "    'clark-county',\n",
    "    'columbus',\n",
    "    'dallas',\n",
    "    'denver',\n",
    "    'hawaii',\n",
    "    'jersey-city',\n",
    "    'los-angeles',\n",
    "    'nashville',\n",
    "    'new-orleans',\n",
    "    'new-york-city',\n",
    "    'oakland',\n",
    "    'pacific-grove',\n",
    "    'palm-springs',\n",
    "    'philadelphia',\n",
    "    'portland',\n",
    "    'raleigh',\n",
    "    'salem',\n",
    "    'san-clara-county',\n",
    "    'san-diego',\n",
    "    'san-francisco',\n",
    "    'san-mateo-county',\n",
    "    'santa-cruz-county',\n",
    "    'santa-monica',\n",
    "    'seattle',\n",
    "    'twin-cities',\n",
    "    'washington-dc'\n",
    "]\n",
    "\n",
    "ingest_data(list_of_cities,list_of_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af2f6bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_csv_gz =pd.read_pickle('listings_csv_gz.pkl')\n",
    "\n",
    "keep_cols = [ 'neighbourhood_cleansed',\n",
    "             'property_type' , \n",
    "             'room_type', \n",
    "             'accommodates',\n",
    "             'bathrooms_text',\n",
    "             'bedrooms',\n",
    "             'beds', \n",
    "             #'amenities',\n",
    "             #'review_scores_rating' \n",
    "             'review_scores_value',\n",
    "             'price',  \n",
    "             'city']\n",
    "\n",
    "def trim_and_encode_listings(listings_csv_gz, keep_cols ):\n",
    "    # Fix pricing\n",
    "    listings_csv_gz.price = listings_csv_gz.price.replace(',','',regex=True\n",
    "                                                     ).replace('\\$','',regex=True).astype('float')\n",
    "\n",
    "\n",
    "\n",
    "    # Also Trim columns with no reviews to remove inactive properties\n",
    "    trimmed_listings = listings_csv_gz.dropna(subset=[\n",
    "                                               'first_review'], how='all', inplace=False)\n",
    "\n",
    "\n",
    "    # drop rows where bathrooms text, bedrooms or beds are null\n",
    "    trimmed_listings = trimmed_listings.dropna(subset=[\n",
    "                                                'bathrooms_text',\n",
    "                                                'bedrooms',\n",
    "                                                'beds',\n",
    "                                                'review_scores_value'],how='any', inplace=False)\n",
    "    \n",
    "    trimmed_listings = trimmed_listings[keep_cols]\n",
    "    trimmed_listings = trimmed_listings[trimmed_listings.review_scores_value > 4.5]\n",
    "#     trimmed_listings = trimmed_listings[trimmed_listings.room_type == 'Entire home/apt']\n",
    "#     trimmed_listings = trimmed_listings[trimmed_listings.property_type.isin(['Entire rental unit',\n",
    "#                                                                              'Entire home',\n",
    "#                                                                              'Entire rental unit',\n",
    "#                                                                              'Entire home',\n",
    "#                                                                              'Entire condo',\n",
    "#                                                                              'Entire guesthouse',\n",
    "#                                                                              'Entire townhouse',\n",
    "#                                                                              'Entire serviced apartment',\n",
    "#                                                                              'Entire loft'])]\n",
    "                                                                             \n",
    "\n",
    "    \n",
    "    def extract_numeric_value(series):\n",
    "\n",
    "        numeric_series = series.apply(lambda x: re.findall(r'\\d+\\.\\d+|\\d+', x))\n",
    "        numeric_series = numeric_series.apply(lambda x: float(x[0]) if len(x) > 0 else 0)\n",
    "        return numeric_series\n",
    "\n",
    "\n",
    "    # Get integer in text:    \n",
    "    trimmed_listings.bathrooms_text =  extract_numeric_value(trimmed_listings.bathrooms_text)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return trimmed_listings\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec6676c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_listings = trim_and_encode_listings(listings_csv_gz, keep_cols )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5e249cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recover listints from pickle\n",
    "# listings_csv_gz =pd.read_pickle('listings_csv_gz.pkl')\n",
    "\n",
    "\n",
    "# Fix pricing\n",
    "# listings_csv_gz.price = listings_csv_gz.price.replace(',','',regex=True\n",
    "#                                                      ).replace('\\$','',regex=True).astype('float')\n",
    "\n",
    "\n",
    "\n",
    "# # Also Trim columns with no reviews to remove inactive properties\n",
    "# trimmed_listings = listings_csv_gz.dropna(subset=[\n",
    "#                                                'first_review'], how='all', inplace=False)\n",
    "\n",
    "\n",
    "# # drop rows where bathrooms text, bedrooms or beds are null\n",
    "# trimmed_listings = trimmed_listings.dropna(subset=[\n",
    "#                                                 'bathrooms_text',\n",
    "#                                                 'bedrooms',\n",
    "#                                                 'beds'],how='any', inplace=False)\n",
    "\n",
    "\n",
    "# keep_cols = [ 'neighbourhood_cleansed',\n",
    "#              'property_type' , \n",
    "#              'room_type', \n",
    "#              'accommodates',\n",
    "#              'bathrooms_text',\n",
    "#              'bedrooms',\n",
    "#              'beds', \n",
    "#              #'amenities',\n",
    "#              'price',  \n",
    "#              'city']\n",
    "\n",
    "# trimmed_listings = trimmed_listings[keep_cols]\n",
    "# trimmed_listings = trimmed_listings[trimmed_listings.room_type == 'Entire home/apt']\n",
    "\n",
    "\n",
    "# create staging pickle to be used as based for Feature engineering.\n",
    "\n",
    "#trimmed_listings.to_pickle('trimmed_listings.pkl')\n",
    "# del listings_csv_gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71492ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_numeric_value(series):\n",
    "#     numeric_series = series.apply(lambda x: re.findall(r'\\d+\\.\\d+|\\d+', x))\n",
    "#     numeric_series = numeric_series.apply(lambda x: float(x[0]) if len(x) > 0 else 0)\n",
    "#     return numeric_series\n",
    "\n",
    "\n",
    "# # Get integer in text:    \n",
    "# trimmed_listings.bathrooms_text =  extract_numeric_value(trimmed_listings.bathrooms_text)\n",
    "\n",
    "\n",
    "# def count_lists(series):\n",
    "#     return series.map(lambda x: 0 if eval(x)== None else len(eval(x)))    \n",
    "\n",
    "# # Count Items in list:\n",
    "# for field in ['amenities']:\n",
    "#     trimmed_listings[field] = count_lists(trimmed_listings[field])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f19169d",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2da4e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoded_listings(df):\n",
    "    \n",
    "\n",
    "    def one_hot_encode(df, column_name):\n",
    "        df_encoded = pd.get_dummies(df, columns=[column_name], prefix=[column_name], drop_first=True)\n",
    "        return df_encoded\n",
    "\n",
    "    # one hot encode:\n",
    "    for column_name in ['room_type', 'neighbourhood_cleansed','city', 'property_type' ]:\n",
    "        df = one_hot_encode(df, column_name)\n",
    "\n",
    "    df.head().to_csv('encoded_listings.csv',index=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f82831bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trimmed_listings.boxplot(column='price')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aedc8fb",
   "metadata": {},
   "source": [
    "4) Create a Grid-Search Function to enable efficient model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f773946c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_grid_search(df, selected_models=None, cv=5, test_size=0.2, n_estimators =[50, 100, 200]):\n",
    "#     # Separate features (X) and target variable (y)\n",
    "#     X = df.drop('price', axis=1)\n",
    "#     y = df['price']\n",
    "\n",
    "#     # Split the data into training and testing sets\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "\n",
    "#     # Perform feature scaling\n",
    "#     scaler = MinMaxScaler()\n",
    "#     X_train_scaled = scaler.fit_transform(X_train)\n",
    "#     X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#     # Define the regression models with their parameter grids\n",
    "#     regressors = {\n",
    "#         'Linear Regression': (LinearRegression(), {}),\n",
    "#         'Ridge': (Ridge(), {'alpha': [0.1, 1.0, 10.0]}),\n",
    "#         'Lasso': (Lasso(tol=0.001, max_iter=2000), {'alpha': [0.1, 1.0, 10.0]}),\n",
    "#         'ElasticNet': (ElasticNet(), {'alpha': [0.1, 1.0, 10.0], 'l1_ratio': [0.25, 0.5, 0.75]}),\n",
    "#         'Decision Tree': (DecisionTreeRegressor(), {'max_depth': [None, 5, 10, 20]}),\n",
    "#         'Random Forest': (RandomForestRegressor(), {'n_estimators': n_estimators}),\n",
    "#         'Gradient Boosting': (GradientBoostingRegressor(), {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 1.0]}),\n",
    "#         'XGBoost': (XGBRegressor(), {'n_estimators': n_estimators, 'learning_rate': [0.01, 0.1, 1.0]}),\n",
    "#         'LightGBM': (LGBMRegressor(), {'n_estimators': n_estimators, 'learning_rate': [0.01, 0.1, 1.0]}),\n",
    "#         'k-NN': (KNeighborsRegressor(), {'n_neighbors': [3, 5, 7, 10, 100]}),\n",
    "#         'Neural Network': (MLPRegressor(), {'hidden_layer_sizes': [(100,), (100, 100), (50, 50, 50)]})\n",
    "#     }\n",
    "\n",
    "#     # train and evaluate each selected regression \n",
    "#     results = {'RMSE': [], 'R-squared': [], 'Best Parameters': [], 'elapsed_time': []}\n",
    "\n",
    "#     if selected_models is None:\n",
    "#         selected_models = regressors.keys()\n",
    "\n",
    "#     for name, (regressor, param_grid) in regressors.items():\n",
    "#         if name in selected_models:\n",
    "#             start = datetime.datetime.now()\n",
    "#             print('Starting ', name, ' - ', start)\n",
    "#             grid_search = GridSearchCV(regressor, param_grid, scoring='neg_mean_squared_error', cv=cv)\n",
    "#             grid_search.fit(X_train_scaled, y_train)\n",
    "#             best_estimator = grid_search.best_estimator_\n",
    "#             best_params = grid_search.best_params_\n",
    "#             predictions = best_estimator.predict(X_test_scaled)\n",
    "#             rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "#             r2 = r2_score(y_test, predictions)\n",
    "#             results['RMSE'].append(rmse)\n",
    "#             results['R-squared'].append(r2)\n",
    "#             results['Best Parameters'].append(best_params)\n",
    "            \n",
    "#             end = datetime.datetime.now()\n",
    "#             elapsed_time = end - start\n",
    "#             results['elapsed_time'].append(elapsed_time)\n",
    "            \n",
    "#             print(name, 'regression complete - ', end, 'elapsed: ', elapsed_time, '-', r2)\n",
    "\n",
    "#     # Create table\n",
    "#     results_df = pd.DataFrame(results, index=selected_models)\n",
    "    \n",
    "#     return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47d705ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_and_save_model( high_cut_off, low_cut_off = 10, no_eval = True):\n",
    "    selected_models = [#'Linear Regression', 'Ridge', 'Lasso', 'ElasticNet', \n",
    "                       'LightGBM']\n",
    "    \n",
    "    # Filtering out records outside the low and high cut-off range\n",
    "    filtered_data = trimmed_listings[(trimmed_listings.price >= low_cut_off) & (trimmed_listings.price <= high_cut_off)]\n",
    "    \n",
    "    # Counting excluded records\n",
    "    excluded = len(trimmed_listings) - len(filtered_data)\n",
    "    print(excluded, 'records excluded')\n",
    "    print(len(filtered_data), 'records included')\n",
    "    filtered_data.to_pickle('filtered_data')\n",
    "    \n",
    "    if no_eval== False:\n",
    "    # Perform model grid search on the filtered data\n",
    "        results = model_grid_search(encoded_listings(filtered_data), selected_models=selected_models)\n",
    "\n",
    "        results['low_cut_off'] = low_cut_off\n",
    "        results['high_cut_off'] = high_cut_off\n",
    "        results['excluded'] = excluded\n",
    "        #results.to_pickle('results_{}_{}.pkl'.format(low_cut_off, high_cut_off))\n",
    "        \n",
    "        return_value= results, filtered_data\n",
    "    \n",
    "    else:\n",
    "        return_value=  filtered_data\n",
    "    \n",
    "    return return_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b4561b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14478101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# high_cut_off = 700\n",
    "# low_cut_off =0\n",
    "# cleaned_data = remove_outliers (high_cut_off, low_cut_off, no_eval =False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbb95d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# for high_cut_off in [2500, 2000, 1500, 1000,700,600]:\n",
    "#     for low_cut_off in [0, 15,20,30, 40, 50]:\n",
    "#         print('\\n====== High:', high_cut_off, '- ===== Low:',low_cut_off)\n",
    "#         remove_outliers (high_cut_off, low_cut_off, no_eval =False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b606cf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_grid_search(df, selected_models=None, cv=5, test_size=0.2, n_estimators=[50, 100, 200]):\n",
    "\n",
    "\n",
    "    # Separate features (X) and target variable (y)\n",
    "    X = df.drop('price', axis=1)\n",
    "    y = df['price']\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "\n",
    "    # Perform feature scaling\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Define the regression models with their parameter grids\n",
    "    regressors = {\n",
    "        'Linear Regression': (LinearRegression(), {}),\n",
    "        'Ridge': (Ridge(), {'alpha': [0.1, 1.0, 10.0]}),\n",
    "        'Lasso': (Lasso(tol=0.001, max_iter=2000), {'alpha': [0.1, 1.0, 10.0]}),\n",
    "        'ElasticNet': (ElasticNet(), {'alpha': [0.1, 1.0, 10.0], 'l1_ratio': [0.25, 0.5, 0.75]}),\n",
    "        'Decision Tree': (DecisionTreeRegressor(), {'max_depth': [None, 5, 10, 20]}),\n",
    "        'Random Forest': (RandomForestRegressor(), {'n_estimators': n_estimators}),\n",
    "        'Gradient Boosting': (GradientBoostingRegressor(), {'n_estimators': n_estimators, 'learning_rate': [0.01, 0.1, 1.0]}),\n",
    "        'XGBoost': (XGBRegressor(), {'n_estimators': n_estimators, 'learning_rate': [0.01, 0.1, 1.0]}),\n",
    "        'LightGBM': (LGBMRegressor(), {'n_estimators': n_estimators, 'learning_rate': [0.01, 0.1, 1.0]}),\n",
    "        'k-NN': (KNeighborsRegressor(), {'n_neighbors': [3, 5, 7, 10, 100]}),\n",
    "        'Neural Network': (MLPRegressor(), {'hidden_layer_sizes': [(100,), (100, 100), (50, 50, 50)]})\n",
    "    }\n",
    "\n",
    "    # Train and evaluate each selected regression \n",
    "    results = {'RMSE': [], 'R-squared': [], 'Best Parameters': [], 'elapsed_time': []}\n",
    "\n",
    "    if selected_models is None:\n",
    "        selected_models = regressors.keys()\n",
    "\n",
    "    for name in selected_models:\n",
    "        regressor, param_grid = regressors[name]\n",
    "        start = datetime.datetime.now()\n",
    "        print('Starting ', name, ' - ', start)\n",
    "        grid_search = GridSearchCV(regressor, param_grid, scoring='neg_mean_squared_error', cv=cv)\n",
    "        grid_search.fit(X_train_scaled, y_train)\n",
    "        best_estimator = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "        predictions = best_estimator.predict(X_test_scaled)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "        r2 = r2_score(y_test, predictions)\n",
    "        results['RMSE'].append(rmse)\n",
    "        results['R-squared'].append(r2)\n",
    "        results['Best Parameters'].append(best_params)\n",
    "        \n",
    "        end = datetime.datetime.now()\n",
    "        elapsed_time = end - start\n",
    "        results['elapsed_time'].append(elapsed_time)\n",
    "        \n",
    "        print(name, 'regression complete - ', end, 'elapsed: ', elapsed_time, '-', r2)\n",
    "\n",
    "        # Save the best performing model\n",
    "        model_filename = f\"{name.lower().replace(' ', '-')}_prod_model.pkl\"\n",
    "        joblib.dump(best_estimator, model_filename)\n",
    "\n",
    "    # Create table\n",
    "    results_df = pd.DataFrame(results, index=selected_models)\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "474f0bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== High: 2000 - ===== Low: 0\n",
      "514 records excluded\n",
      "124368 records included\n",
      "Starting  LightGBM  -  2023-12-03 20:28:09.101336\n",
      "LightGBM regression complete -  2023-12-03 20:30:17.703122 elapsed:  0:02:08.601786 - 0.5638900790831248\n",
      "\n",
      "====== High: 2000 - ===== Low: 15\n",
      "544 records excluded\n",
      "124338 records included\n",
      "Starting  LightGBM  -  2023-12-03 20:30:25.141541\n",
      "LightGBM regression complete -  2023-12-03 20:32:15.125135 elapsed:  0:01:49.983594 - 0.563855660185334\n",
      "\n",
      "====== High: 2000 - ===== Low: 30\n",
      "618 records excluded\n",
      "124264 records included\n",
      "Starting  LightGBM  -  2023-12-03 20:32:21.390691\n",
      "LightGBM regression complete -  2023-12-03 20:34:12.328229 elapsed:  0:01:50.937538 - 0.5761586318293364\n",
      "\n",
      "====== High: 2000 - ===== Low: 45\n",
      "1039 records excluded\n",
      "123843 records included\n",
      "Starting  LightGBM  -  2023-12-03 20:34:18.617960\n",
      "LightGBM regression complete -  2023-12-03 20:36:19.096478 elapsed:  0:02:00.478518 - 0.571462660515377\n",
      "\n",
      "====== High: 1500 - ===== Low: 0\n",
      "995 records excluded\n",
      "123887 records included\n",
      "Starting  LightGBM  -  2023-12-03 20:36:25.487353\n",
      "LightGBM regression complete -  2023-12-03 20:38:10.716739 elapsed:  0:01:45.229386 - 0.5497054063837974\n",
      "\n",
      "====== High: 1500 - ===== Low: 15\n",
      "1025 records excluded\n",
      "123857 records included\n",
      "Starting  LightGBM  -  2023-12-03 20:38:17.448450\n",
      "LightGBM regression complete -  2023-12-03 20:40:27.125664 elapsed:  0:02:09.677214 - 0.5614440768348601\n",
      "\n",
      "====== High: 1500 - ===== Low: 30\n",
      "1099 records excluded\n",
      "123783 records included\n",
      "Starting  LightGBM  -  2023-12-03 20:40:34.226362\n",
      "LightGBM regression complete -  2023-12-03 20:42:16.455637 elapsed:  0:01:42.229275 - 0.553778154784252\n",
      "\n",
      "====== High: 1500 - ===== Low: 45\n",
      "1520 records excluded\n",
      "123362 records included\n",
      "Starting  LightGBM  -  2023-12-03 20:42:23.040352\n",
      "LightGBM regression complete -  2023-12-03 20:44:50.432247 elapsed:  0:02:27.391895 - 0.5646401635455789\n",
      "\n",
      "====== High: 1000 - ===== Low: 0\n",
      "2349 records excluded\n",
      "122533 records included\n",
      "Starting  LightGBM  -  2023-12-03 20:44:57.479994\n",
      "LightGBM regression complete -  2023-12-03 20:46:52.607731 elapsed:  0:01:55.127737 - 0.5474134579860633\n",
      "\n",
      "====== High: 1000 - ===== Low: 15\n",
      "2379 records excluded\n",
      "122503 records included\n",
      "Starting  LightGBM  -  2023-12-03 20:46:59.869540\n",
      "LightGBM regression complete -  2023-12-03 20:48:48.075928 elapsed:  0:01:48.206388 - 0.5416790203716495\n",
      "\n",
      "====== High: 1000 - ===== Low: 30\n",
      "2453 records excluded\n",
      "122429 records included\n",
      "Starting  LightGBM  -  2023-12-03 20:48:54.322299\n",
      "LightGBM regression complete -  2023-12-03 20:50:44.928721 elapsed:  0:01:50.606422 - 0.5433915910619236\n",
      "\n",
      "====== High: 1000 - ===== Low: 45\n",
      "2874 records excluded\n",
      "122008 records included\n",
      "Starting  LightGBM  -  2023-12-03 20:50:52.912869\n",
      "LightGBM regression complete -  2023-12-03 20:52:37.799821 elapsed:  0:01:44.886952 - 0.5390377517083007\n",
      "\n",
      "====== High: 700 - ===== Low: 0\n",
      "5322 records excluded\n",
      "119560 records included\n",
      "Starting  LightGBM  -  2023-12-03 20:52:44.772094\n",
      "LightGBM regression complete -  2023-12-03 20:54:26.138433 elapsed:  0:01:41.366339 - 0.5317729935657264\n",
      "\n",
      "====== High: 700 - ===== Low: 15\n",
      "5352 records excluded\n",
      "119530 records included\n",
      "Starting  LightGBM  -  2023-12-03 20:54:32.480677\n",
      "LightGBM regression complete -  2023-12-03 20:56:12.901379 elapsed:  0:01:40.420702 - 0.5365595274338548\n",
      "\n",
      "====== High: 700 - ===== Low: 30\n",
      "5426 records excluded\n",
      "119456 records included\n",
      "Starting  LightGBM  -  2023-12-03 20:56:19.001267\n",
      "LightGBM regression complete -  2023-12-03 20:57:58.341214 elapsed:  0:01:39.339947 - 0.5205015264960768\n",
      "\n",
      "====== High: 700 - ===== Low: 45\n",
      "5847 records excluded\n",
      "119035 records included\n",
      "Starting  LightGBM  -  2023-12-03 20:58:04.928529\n",
      "LightGBM regression complete -  2023-12-03 20:59:48.420349 elapsed:  0:01:43.491820 - 0.5250031145327809\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for high_cut_off in [2000, 1500, 1000,700]:\n",
    "    for low_cut_off in [0, 15,30, 45]:\n",
    "        print('\\n====== High:', high_cut_off, '- ===== Low:',low_cut_off)\n",
    "        remove_outliers (high_cut_off, low_cut_off, no_eval =False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3042f28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e39367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6f8efad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filtered_data = pd.read_csv('app/filtered_data.csv',nrows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>neighbourhood_cleansed</th>\n",
       "      <th>property_type</th>\n",
       "      <th>room_type</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms_text</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>price</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, neighbourhood_cleansed, property_type, room_type, accommodates, bathrooms_text, bedrooms, beds, review_scores_value, price, city]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.drop(filtered_data.index, inplace=True)\n",
    "filtered_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>neighbourhood_cleansed</th>\n",
       "      <th>property_type</th>\n",
       "      <th>room_type</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms_text</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>price</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>78702</td>\n",
       "      <td>Entire home</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.83</td>\n",
       "      <td>183.0</td>\n",
       "      <td>austin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Unincorporated Areas</td>\n",
       "      <td>Entire home</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>13</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>204.0</td>\n",
       "      <td>clark-county</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Primary Urban Center</td>\n",
       "      <td>Entire condo</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.60</td>\n",
       "      <td>137.0</td>\n",
       "      <td>hawaii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Hallandale Beach</td>\n",
       "      <td>Entire rental unit</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>68.0</td>\n",
       "      <td>broward-county</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>78702</td>\n",
       "      <td>Entire home</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.76</td>\n",
       "      <td>421.0</td>\n",
       "      <td>austin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 neighbourhood_cleansed       property_type        room_type  \\\n",
       "0           0                  78702         Entire home  Entire home/apt   \n",
       "1           2   Unincorporated Areas         Entire home  Entire home/apt   \n",
       "2           4   Primary Urban Center        Entire condo  Entire home/apt   \n",
       "3           5       Hallandale Beach  Entire rental unit  Entire home/apt   \n",
       "4           7                  78702         Entire home  Entire home/apt   \n",
       "\n",
       "   accommodates  bathrooms_text  bedrooms  beds  review_scores_value  price  \\\n",
       "0             8             2.5       3.0   4.0                 4.83  183.0   \n",
       "1            13             2.5       4.0   7.0                 5.00  204.0   \n",
       "2             4             1.0       1.0   2.0                 4.60  137.0   \n",
       "3             3             1.0       1.0   1.0                 5.00   68.0   \n",
       "4             6             2.0       3.0   6.0                 4.76  421.0   \n",
       "\n",
       "             city  \n",
       "0          austin  \n",
       "1    clark-county  \n",
       "2          hawaii  \n",
       "3  broward-county  \n",
       "4          austin  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "encoded_data = pd.read_csv('app/encoded_listings.csv',nrows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms_text</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>price</th>\n",
       "      <th>room_type_Hotel room</th>\n",
       "      <th>room_type_Private room</th>\n",
       "      <th>neighbourhood_cleansed_28715</th>\n",
       "      <th>neighbourhood_cleansed_28732</th>\n",
       "      <th>...</th>\n",
       "      <th>property_type_Shepherd’s hut</th>\n",
       "      <th>property_type_Shipping container</th>\n",
       "      <th>property_type_Tent</th>\n",
       "      <th>property_type_Tiny home</th>\n",
       "      <th>property_type_Tipi</th>\n",
       "      <th>property_type_Tower</th>\n",
       "      <th>property_type_Train</th>\n",
       "      <th>property_type_Treehouse</th>\n",
       "      <th>property_type_Windmill</th>\n",
       "      <th>property_type_Yurt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.61</td>\n",
       "      <td>622.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>183.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.85</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.75</td>\n",
       "      <td>146.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.74</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1486 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   accommodates  bathrooms_text  bedrooms  beds  review_scores_value  price  \\\n",
       "0             4             1.0       2.0   2.0                 4.61  622.0   \n",
       "1             4             2.0       2.0   2.0                 5.00  183.0   \n",
       "2             4             3.0       2.0   2.0                 4.85  145.0   \n",
       "3             4             1.0       1.0   1.0                 4.75  146.0   \n",
       "4             4             1.0       2.0   3.0                 4.74   35.0   \n",
       "\n",
       "   room_type_Hotel room  room_type_Private room  neighbourhood_cleansed_28715  \\\n",
       "0                     0                       0                             0   \n",
       "1                     0                       0                             0   \n",
       "2                     0                       0                             0   \n",
       "3                     0                       0                             0   \n",
       "4                     0                       0                             0   \n",
       "\n",
       "   neighbourhood_cleansed_28732  ...  property_type_Shepherd’s hut  \\\n",
       "0                             0  ...                             0   \n",
       "1                             0  ...                             0   \n",
       "2                             0  ...                             0   \n",
       "3                             0  ...                             0   \n",
       "4                             0  ...                             0   \n",
       "\n",
       "   property_type_Shipping container  property_type_Tent  \\\n",
       "0                                 0                   0   \n",
       "1                                 0                   0   \n",
       "2                                 0                   0   \n",
       "3                                 0                   0   \n",
       "4                                 0                   0   \n",
       "\n",
       "   property_type_Tiny home  property_type_Tipi  property_type_Tower  \\\n",
       "0                        0                   0                    0   \n",
       "1                        0                   0                    0   \n",
       "2                        0                   0                    0   \n",
       "3                        0                   0                    0   \n",
       "4                        0                   0                    0   \n",
       "\n",
       "   property_type_Train  property_type_Treehouse  property_type_Windmill  \\\n",
       "0                    0                        0                       0   \n",
       "1                    0                        0                       0   \n",
       "2                    0                        0                       0   \n",
       "3                    0                        0                       0   \n",
       "4                    0                        0                       0   \n",
       "\n",
       "   property_type_Yurt  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  \n",
       "\n",
       "[5 rows x 1486 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "city='los-angeles'\n",
    "neighborhood='Downtown'\n",
    "property_type='Entire condo'\n",
    "room_type = 'Entire home/apt'\n",
    "bathrooms = 1\n",
    "bedrooms = 1\n",
    "beds = 2\n",
    "accommodates= 2\n",
    "\n",
    "\n",
    "\n",
    "input_data = pd.DataFrame([[neighborhood, property_type, room_type, accommodates, bathrooms, bedrooms, beds, city]],\n",
    "                            columns=['neighbourhood_cleansed', \n",
    "                            'property_type', \n",
    "                            'room_type', \n",
    "                            'accommodates',\n",
    "                             'bathrooms_text', \n",
    "                             'bedrooms', \n",
    "                             'beds', \n",
    "                             'city'])\n",
    "\n",
    "\n",
    "input_data_encoded=pd.get_dummies(input_data, \n",
    "                                    columns=['neighbourhood_cleansed', \n",
    "                            'property_type', \n",
    "                            'room_type',            \n",
    "                             'city'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "\n",
    "\n",
    "\n",
    "city='los-angeles'\n",
    "neighborhood='Downtown'\n",
    "property_type='Entire condo'\n",
    "room_type = 'Entire home/apt'\n",
    "bathrooms = 2\n",
    "bedrooms = 3\n",
    "beds = 10\n",
    "accommodates= 4\n",
    "\n",
    "def make_prediction(neighborhood, \n",
    "                    property_type, \n",
    "                    room_type, \n",
    "                    accommodates, \n",
    "                    bathrooms, \n",
    "                    bedrooms, \n",
    "                    beds, \n",
    "                    city):\n",
    "\n",
    "    input_data = pd.DataFrame([[neighborhood, property_type, room_type, accommodates, bathrooms, bedrooms, beds, city]],\n",
    "                                columns=['neighbourhood_cleansed', \n",
    "                                'property_type', \n",
    "                                'room_type', \n",
    "                                'accommodates',\n",
    "                                'bathrooms_text', \n",
    "                                'bedrooms', \n",
    "                                'beds', \n",
    "                                'city'])\n",
    "\n",
    "\n",
    "    input_data_encoded=pd.get_dummies(input_data, \n",
    "                                        columns=['neighbourhood_cleansed', \n",
    "                                'property_type', \n",
    "                                'room_type',            \n",
    "                                'city'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    X_train=pd.read_csv('app/X_train.csv') \n",
    "\n",
    "    missing_cols = set(X_train.columns) - set(input_data_encoded.columns)\n",
    "    for c in missing_cols:\n",
    "        input_data_encoded[c] = 0\n",
    "    input_data_encoded = input_data_encoded[X_train.columns]\n",
    "\n",
    "\n",
    "    scaler = joblib.load('app/scaler.pkl')\n",
    "\n",
    "    input_data_encoded_scaled = scaler.transform(input_data_encoded)\n",
    "\n",
    "\n",
    "    # Load your trained LightGBM model\n",
    "    model = joblib.load('lightgbm_prod_model.pkl')\n",
    "\n",
    "    prediction = model.predict(input_data_encoded_scaled)\n",
    "\n",
    "    return prediction \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexmoura/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([175.52303874])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city='seattle'\n",
    "neighborhood='Downtown'\n",
    "property_type='Entire condo'\n",
    "room_type = 'Entire home/apt'\n",
    "bathrooms = 1\n",
    "bedrooms = 2\n",
    "beds = 10\n",
    "accommodates= 4\n",
    "\n",
    "make_prediction(neighborhood, \n",
    "                    property_type, \n",
    "                    room_type, \n",
    "                    accommodates, \n",
    "                    bathrooms, \n",
    "                    bedrooms, \n",
    "                    beds, \n",
    "                    city)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([248.03952492])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "   prediction = model.predict(input_data_encoded_scaled)\n",
    "   prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
