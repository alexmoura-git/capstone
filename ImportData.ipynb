{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe1e7495",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from config import url, list_of_cities,list_of_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f216f98b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e8c58d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b4267fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def GetData(url, list_of_cities, list_of_files):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import os\n",
    "    import pickle\n",
    "\n",
    "    ## This script gets a list of cities and file names and downloads it from the page only when the data changes\n",
    "    processed_links = []\n",
    "\n",
    "    # Check if the pickle file with lisnks exist\n",
    "    if not os.path.isfile('processed_links.pkl'):\n",
    "        # If the file does not exist, create an empty list and save it to the file\n",
    "        with open('processed_links.pkl', 'wb') as file:\n",
    "            pickle.dump(processed_links, file)\n",
    "    else:\n",
    "        with open('processed_links.pkl', 'rb') as pickle_file:\n",
    "            processed_links = pickle.load(pickle_file)\n",
    "\n",
    "    # Send get request\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "\n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Get Page Links\n",
    "    links = [a['href'] for a in soup.find_all('a', href=True) if a.text]\n",
    "\n",
    "    # Filter only links that end with desired file names\n",
    "    filtered_links =[]\n",
    "\n",
    "    for link in links:\n",
    "        # Download files if the link ends with any of the file names in your list\n",
    "        if any(city.lower() in link.lower() for city in list_of_cities):\n",
    "            if any(link.endswith(file_name) for file_name in list_of_files):\n",
    "                filtered_links.append(link)\n",
    "\n",
    "\n",
    "    # Get not seen links for download          \n",
    "    new_links = [link for link in filtered_links if link not in processed_links]\n",
    "\n",
    "    processed_links = filtered_links\n",
    "    with open('processed_links.pkl', 'wb') as file:\n",
    "            pickle.dump(processed_links, file)\n",
    "\n",
    "    for city in list_of_cities:\n",
    "        folder_name = 'data/'+ city\n",
    "        if not os.path.exists(folder_name):\n",
    "                    os.makedirs(folder_name)\n",
    "\n",
    "        for link in new_links:\n",
    "            if city.lower() in link.lower():\n",
    "                response = requests.get(link)\n",
    "                response.raise_for_status() \n",
    "\n",
    "                filename = os.path.join(folder_name, link.split('/')[-1])\n",
    "                with open(filename, 'wb') as file:\n",
    "                    file.write(response.content)\n",
    "                print(f'Downloaded {filename} to {folder_name}')\n",
    "                \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d87f8441",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded data/asheville/listings.csv.gz to data/asheville\n",
      "Downloaded data/austin/listings.csv.gz to data/austin\n",
      "Downloaded data/boston/listings.csv.gz to data/boston\n",
      "Downloaded data/broward-county/listings.csv.gz to data/broward-county\n",
      "Downloaded data/cambridge/listings.csv.gz to data/cambridge\n",
      "Downloaded data/chicago/listings.csv.gz to data/chicago\n",
      "Downloaded data/clark-county/listings.csv.gz to data/clark-county\n",
      "Downloaded data/columbus/listings.csv.gz to data/columbus\n",
      "Downloaded data/dallas/listings.csv.gz to data/dallas\n",
      "Downloaded data/denver/listings.csv.gz to data/denver\n",
      "Downloaded data/hawaii/listings.csv.gz to data/hawaii\n",
      "Downloaded data/jersey-city/listings.csv.gz to data/jersey-city\n",
      "Downloaded data/los-angeles/listings.csv.gz to data/los-angeles\n",
      "Downloaded data/nashville/listings.csv.gz to data/nashville\n",
      "Downloaded data/new-orleans/listings.csv.gz to data/new-orleans\n",
      "Downloaded data/new-york-city/listings.csv.gz to data/new-york-city\n",
      "Downloaded data/oakland/listings.csv.gz to data/oakland\n",
      "Downloaded data/pacific-grove/listings.csv.gz to data/pacific-grove\n",
      "Downloaded data/portland/listings.csv.gz to data/portland\n",
      "Downloaded data/salem/listings.csv.gz to data/salem\n",
      "Downloaded data/san-diego/listings.csv.gz to data/san-diego\n",
      "Downloaded data/san-francisco/listings.csv.gz to data/san-francisco\n",
      "Downloaded data/san-mateo-county/listings.csv.gz to data/san-mateo-county\n",
      "Downloaded data/santa-cruz-county/listings.csv.gz to data/santa-cruz-county\n",
      "Downloaded data/seattle/listings.csv.gz to data/seattle\n",
      "Downloaded data/twin-cities/listings.csv.gz to data/twin-cities\n",
      "Downloaded data/washington-dc/listings.csv.gz to data/washington-dc\n"
     ]
    }
   ],
   "source": [
    "GetData(url, list_of_cities, list_of_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af70ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
